{# apps/ui/templates/technology.html #}
{% extends "base.html" %}

{% block title %}Technology · A3CP by GestureLabs{% endblock %}

{% block content %}

{# --- Intro section via centered text block --- #}
{% set ct_eyebrow = "Technology" %}
{% set ct_headline = "How A3CP turns multimodal signals into adaptive communication." %}
{% set ct_subheadline = "
The Ability-Adaptive Augmentative Communication Platform (A3CP) turns movements and sounds into communication with
help from caregivers. It is built from clear, separate parts so the system can be understood, checked, and improved over
time.
" %}
{% include "components/_centered_text_block.html" %}

{# --- End-to-End Pipeline Illustration --- #}
{% set ci_src = "/static/img/illustrations/Architecture_Diagram.png" %}
{% set ci_alt = "A3CP pipeline from multimodal inputs through classification, CARE Engine decision logic, output, and
feedback." %}
{% set ci_caption = "End-to-end A3CP pipeline." %}
{% set ci_size = "lg" %}

{% include "components/_centered_image_var.html" %}




{# --- Modular architecture via six-block grid --- #}
{% set sbg_title = "Modular Architecture" %}
{% set sbg_intro = "
A3CP is built as a modular framework: each component operates independently and communicates through shared data
standards. This makes the system easier to audit, extend, and deploy across care, therapy, and educational environments.
" %}

{% set sbg_items = [
{
"title": "1. Capture Layer",
"text": "Camera and microphone inputs collected locally for low-latency, privacy-preserving processing."
},
{
"title": "2. Feature Extraction",
"text": "Landmarks, movement features, and audio features converted into compact numeric vectors."
},
{
"title": "3. Classification",
"text": "User-specific models generate intent predictions with calibrated confidence scores."
},
{
"title": "4. CARE Engine",
"text": "Fuses predictions, checks uncertainty, and triggers caregiver clarification when needed."
},
{
"title": "5. Memory & Learning",
"text": "Stores caregiver-confirmed examples so the system gradually adapts to the user’s patterns."
},
{
"title": "6. Interface Layer",
"text": "Drives speech, text, or symbol output and can explain uncertainty or request confirmation."
}
] %}

{% include "components/_six_block_grid.html" %}


{# --- CARE Engine: centered text + centered schematic --- #}

{# Text block #}
{% set ct_eyebrow = "Core Logic" %}
{% set ct_headline = "The CARE Engine" %}
{% set ct_subheadline = "
The CARE Engine (Clarification, Adaptation, Reasoning, and Explanation) is the decision core of A3CP.
It combines predictions from gesture, sound, and contextual models, evaluates confidence, and determines
when human clarification is required.
When certainty is low, it presents plausible interpretations instead of committing to a single guess,
keeping caregivers in control while enabling safe, individualized learning over time.
" %}
{% include "components/_centered_text_block.html" %}

{% set ci_src = "/static/img/illustrations/Care_Engine.png" %}
{% set ci_alt = "CARE Engine schematic showing fusion of multimodal predictions, confidence gating, clarification, and
memory updates." %}
{% set ci_caption = "The CARE Engine uses confidence-aware reasoning and caregiver confirmation to guide safe
adaptation." %}
{% set ci_size = "sm" %}
{% set ci_muted = true %}

{% include "components/_centered_image_var.html" %}


{# --- Ethical and Edge-Capable Design: centered text + centered image --- #}

{% set ct_eyebrow = "Deployment" %}
{% set ct_headline = "Ethical and Edge-Capable Design" %}
{% set ct_subheadline = "
A3CP is engineered to preserve privacy, remain inspectable, and support multiple deployment modes:
edge-only, cloud, or hybrid edge with optional cloud-based updating.

In edge deployments, inference runs locally on affordable devices. In hybrid mode, the system can run locally
while optionally synchronizing model updates or configuration changes when connectivity is available.

Only derived feature data are stored — never raw video or audio — so learning and adaptation remain
transparent and explainable. Code and documentation are open source, enabling independent review,
replication, and improvement, and reducing vendor lock-in.
" %}
{% include "components/_centered_text_block.html" %}

{% set ci_src = "/static/img/illustrations/Cloud_Edge.png" %}
{% set ci_alt = "Diagram showing A3CP deployment options: edge-only, cloud, and hybrid edge with cloud-based updates."
%}
{% set ci_caption = "Deployment modes: edge-only, cloud, or hybrid edge inference with optional cloud updating." %}
{% set ci_size = "md" %}
{% set ci_muted = true %}
{% include "components/_centered_image_var.html" %}



{# Development Path as three-card row #}
{% set tcr_title = "Development Path" %}
{% set tcr_intro = "A3CP has progressed through successive prototypes toward a stable, deployable system." %}

{% set tcr_cards = [
{
"title": "Phase 1",
"description": "Streamlit demonstrator validated feasibility of gesture capture, landmark visualization, and
personalized training.",
"href": "/docs"
},
{
"title": "Phase 2",
"description": "Modular FastAPI architecture established a scalable foundation for real-world deployment.",
"href": "/docs"
},
{
"title": "Phase 3 (2026)",
"description": "Integration of gesture and sound classifiers, caregiver-in-the-loop training, and early pilot studies.",
"href": "/docs"
}
] %}

{% include "components/_three_card_row.html" %}




{# --- Future Possibilities (intro) --- #}
{% set ct_eyebrow = "Vision" %}
{% set ct_headline = "Future Possibilities" %}
{% set ct_subheadline = "A3CP’s adaptive architecture can support creative, therapeutic, and research applications.
Because interactions can be represented as structured, interpretable data, the same pipeline that supports communication
can also support learning, creativity, and longitudinal insight." %}

{% include "components/_centered_text_block.html" %}


{# --- 1) Gesture-based music or art composition --- #}
{% set headline = "Gesture-based music or art composition" %}
{% set body_html %}
<p>
    Embodied signals can be mapped to musical and visual outputs, enabling creative expression through accessible,
    user-specific interactions rather than conventional instruments or fine motor control.
</p>
{% endset %}
{% set img_src = "/static/img/illustrations/Embodied_Creativity.png" %}
{% set img_alt = "A wheelchair user uses gestures to control music and art elements shown on a screen." %}
{% set caption = "Creative expression through gesture-to-parameter mapping." %}
{% set reverse = false %}
{% include "components/_two_column_text_w_photo.html" %}


{# --- 2) Integration with digital avatars and embodied interfaces --- #}
{% set headline = "Integration with digital avatars and embodied interfaces" %}
{% set body_html %}
<p>
    Interpreted intent can control avatars for online communication, allowing users to choose their
    representation while maintaining control of meaning and interaction across distance.
</p>
{% endset %}
{% set img_src = "/static/img/illustrations/Embodied_Avatars.png" %}
{% set img_alt = "A user’s embodied interaction drives an outward-facing avatar used for online communication." %}
{% set caption = "Chosen representation for online presence." %}
{% set reverse = true %}
{% include "components/_two_column_text_w_photo.html" %}


{# --- 3) Adaptive learning tools for therapy and education --- #}
{% set headline = "Adaptive learning tools for therapy and education" %}
{% set body_html %}
<p>
    The same uncertainty-aware feedback loop can support learning activities by adapting task difficulty, input
    mappings, and prompts to the individual, helping to learn new gestures and develop communication abilities.
</p>
{% endset %}
{% set img_src = "/static/img/illustrations/Learning_Tools.png" %}
{% set img_alt = "A learner and partner use an adaptive activity on a screen with structured confirmation." %}
{% set caption = "Adaptive tasks with partner-in-the-loop confirmation." %}
{% set reverse = false %}
{% include "components/_two_column_text_w_photo.html" %}


{# --- 4) Longitudinal analytics for clinical teams --- #}
{% set headline = "Longitudinal analytics for clinical teams" %}
{% set body_html %}
<p>
    Aggregated summaries over weeks and months can support clinical review by showing trends in interaction success,
    uncertainty rates, and confirmed intent.
</p>
{% endset %}
{% set img_src = "/static/img/illustrations/Longitudinal_Analytics.png" %}
{% set img_alt = "Clinical team reviewing longitudinal trends and summaries on a shared display." %}
{% set caption = "Trends and summaries for clinical review." %}
{% set reverse = true %}
{% include "components/_two_column_text_w_photo.html" %}


{# --- 5) Multimodal datasets for research on communication development --- #}
{% set headline = "Multimodal datasets for research on communication development" %}
{% set body_html %}
<p>
    Structured traces can support research datasets that link context, model outputs, clarification
    outcomes, and confirmed intent, enabling studies of communication development over time.
</p>
{% endset %}
{% set img_src = "/static/img/illustrations/Multimodal_Datasets.png" %}
{% set img_alt = "Panels representing multimodal dataset components derived from structured interaction traces." %}
{% set caption = "Multimodal datasets derived from structured interaction traces." %}
{% set reverse = false %}
{% include "components/_two_column_text_w_photo.html" %}





{% endblock %}
