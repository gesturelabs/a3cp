{% extends "base.html" %}

{% block title %}About GestureLabs · A3CP{% endblock %}

{% block content %}

{# PURPOSE #}
{% set ct_headline = "Why GestureLabs is building the Ability-Adaptive Communication Platform (A3CP)" %}
{% set ct_subheadline %}
A3CP is an open-source communication platform for people who cannot rely on speech. We work with families, clinicians,
and care organisations to build systems that learn how each person communicates—through movement, sound, and
context—rather than forcing them to adapt to rigid interfaces.
{% endset %}
{% include "components/_centered_text_block.html" %}


{# CHALLENGE / APPROACH / IMPACT #}
{% set tcr_title = "What problem A3CP is trying to solve" %}
{% set tcr_intro %}
Across Europe, many people with severe motor or cognitive disabilities still lack reliable ways to communicate. Current
assistive-communication tools often assume abilities—precise pointing, eye-tracking, symbol selection—that many do not
have. A3CP is our attempt to close this gap.
{% endset %}
{% set tcr_cards = [
{
"title": "The challenge",
"description": "Non-speaking people are often asked to fit into technology that was not designed for them. Systems built
around fixed input methods can leave individuals isolated and caregivers overwhelmed, especially in understaffed welfare
institutions.",
"href": None
},
{
"title": "Our approach",
"description": "A3CP is a modular, open-source platform that learns each person’s patterns of movement, sound, and
context. Caregivers remain in the loop: they label gestures, confirm meanings, and guide how the system adapts over
time.",
"href": "/technology"
},
{
"title": "The impact we aim for",
"description": "By making ability-adaptive communication infrastructure openly available, we want to enable non-speaking
people to express needs and preferences, reduce caregiver stress, and give welfare organisations tools they can audit,
extend, and trust.",
"href": "/impact"
}
] %}
{% include "components/_three_card_row.html" %}


{# STORY WITH PHOTO #}
<section class="section section-story">
    <div class="story-inner">
        <div class="story-text">
            <h2>Where A3CP came from</h2>
            <p>
                A3CP began with a family’s experience. Andrea’s son Eric, a bright and curious child with cerebral
                palsy,
                understands two languages and communicates through sound, movement, and expression—but does not yet
                speak.
                Everyday interactions made two things clear: the richness of his non-verbal communication, and the
                limits of
                existing assistive systems that required him to adapt to fixed input methods he could not reliably
                control.
            </p>
            <p>
                Andrea’s wish to give her son a voice initiated a collaboration between technologists, designers, and
                researchers at The Open University (UK). Early prototypes combined simple sensors, gesture recognition,
                and
                participatory design with families and therapists. These experiments showed that even low-cost
                technology
                can capture meaningful signals when it is designed around individual ability.
            </p>
            <p>
                GestureLabs was founded in Berlin to carry this work forward as a non-profit initiative. A3CP is now
                being
                developed as open, transparent infrastructure that care organisations, researchers, and families can
                freely
                use, improve, and share.
            </p>
        </div>

        <figure class="story-photo">
            <img src="/static/img/photos/andrea_erik2.png"
                alt="Andrea with her son Eric during a communication session">
            <figcaption>
                Andrea and her son Eric. Their experience helped shape the core ideas behind A3CP.
            </figcaption>
        </figure>
    </div>
</section>


{# WHAT WE ARE BUILDING #}
{% set tcr_title = "What we are building" %}
{% set tcr_intro %}
The Ability-Adaptive Augmentative Communication Platform is not a single app, but a stack of components that can be
deployed in schools, care homes, therapy centres, and family homes.
{% endset %}
{% set tcr_cards = [
{
"title": "Inputs: gestures, sound, context",
"description": "A3CP takes in signals from cameras, microphones, and other sensors, turning movement, vocalisation, and
environmental context into structured representations. The goal is to work with affordable, widely available hardware.",
"href": "/technology#inputs"
},
{
"title": "Learning with caregivers",
"description": "The platform learns over time how a specific person uses gestures and sounds to express meaning.
Caregivers can label new actions, correct mistakes, and see how the system is changing—keeping humans in control of
interpretation.",
"href": "/technology#learning"
},
{
"title": "Outputs and integration",
"description": "Recognised intents can be rendered as speech, text, or symbols and integrated with existing AAC tools
where appropriate. The modular FastAPI-based stack and documented schemas are designed for extension and audit.",
"href": "/technology#outputs"
}
] %}
{% include "components/_three_card_row.html" %}


{# HOW WE WORK / PRINCIPLES #}
{% set vl_label = "How we work" %}
{% set vl_title = "What we value and how we design A3CP" %}
{% set vl_intro = "Shaping an adaptive communication system for non-speaking people requires principled choices about
data, design, and governance." %}
{% set vl_values = [
{"number": 1, "title": "Put the person first.", "text": "We design around individual abilities and contexts, not around
standardised gestures or abstract user models."},
{"number": 2, "title": "Caregiver-in-the-loop.", "text": "Caregivers label new actions, correct interpretations, and
review how the system adapts over time."},
{"number": 3, "title": "Open and inspectable.", "text": "Schemas, logs, and code are open so institutions can audit
behaviour and adapt the platform to their needs."},
{"number": 4, "title": "Privacy and safety by design.", "text": "We prioritise local processing, data minimisation, and
clear documentation of how information flows."},
{"number": 5, "title": "Scientific and clinical rigour.", "text": "We work with researchers, clinicians, and families
using transparent methods and reproducible protocols."}
] %}
{% include "components/_values_list.html" %}



{# CURRENT STATUS #}
<section class="section">
    <h2>Where the project is today</h2>
    <ul>
        <li>Core architecture defined using a modular FastAPI-based stack.</li>
        <li>Canonical data schemas validated with Pydantic v2 and documented for partners.</li>
        <li>Adaptive memory and caregiver-feedback framework designed and under active implementation.</li>
        <li>Collaboration network forming in Berlin–Brandenburg and internationally.</li>
        <li>Pilot studies with care and research partners planned for 2026.</li>
    </ul>
</section>


{# CTA BAND #}
{% set ctab_headline = "Interested in collaborating on A3CP?" %}
{% set ctab_subtext %}
We are looking for partners in care, research, engineering, and policy who want to help shape ability-adaptive
communication technology as open, transparent infrastructure.
{% endset %}
{% set ctab_primary_label = "Contact GestureLabs" %}
{% set ctab_primary_href = "/contact" %}
{% set ctab_secondary_label = "Read the technical documentation" %}
{% set ctab_secondary_href = "/docs" %}
{% include "components/_cta_band.html" %}

{% endblock %}
