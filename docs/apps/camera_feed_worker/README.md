# Submodule: camera_feed_worker

### Deprecate superseded by apps/module



## Purpose
Ingests bounded video capture windows from a capture client (Sprint 1: browser via WebSocket) and streams them to downstream modules in real time.
Acts as the ingest boundary for all client-derived video data such as landmarks, classification, and recording.



| Field             | Value                  |
|------------------|------------------------|
| **Module Name**  | `camera_feed_worker`   |
| **Module Type**  | `worker`               |
| **Inputs From**  | capture client (Sprint 1: browser via WebSocket), `session_manager` (session_id policy) |
| **Outputs To**   |`landmark_extractor` and other downstream vision modules/classifiers (e.g., object detection); `schema_recorder` only indirectly via downstream emitters |
| **Produces A3CPMessage?** | ❌ No |
WebSocket control messages (e.g., `capture.open`, `capture.frame_meta`, `capture.close`)
reuse a subset of BaseSchema-style metadata fields (`schema_version`, `record_id`,
`user_id`, `session_id`) strictly as transport metadata. These are NOT
A3CPMessage records and are not written via `schema_recorder`.




## Responsibilities
- Accept bounded capture windows from a capture client (Sprint 1: browser via WebSocket)
- Enforce server-side guardrails (duration, FPS, resolution, total frames/bytes)
- Validate and preserve event-time timestamps supplied by the capture client
- Optionally attach ingest-time timestamps for diagnostics (must not overwrite event-time)
- Validate and propagate capture/session metadata
- Forward frames or window payload to downstream consumers (e.g., `LandmarkExtractor`)
- Signal ingest errors or capture failures to orchestrating modules


## Not Responsible For
- Landmark extraction or classification
- File I/O or schema-compliant recording
- Inference or decision-making logic
- Intent capture or session coordination

## Inputs
- WebSocket capture messages from a capture client (Sprint 1: browser):
  - `capture.open` (window metadata and capture parameters)
 - `capture.frame_meta` (JSON; per-frame metadata)
- `capture.frame_bytes` (binary; JPEG frame bytes immediately following the corresponding frame_meta message; byte_length must match)

  - `capture.close` (window termination)

- Required metadata:
  - `user_id`
  - `session_id` (explicit; must be provided; validation as active session is a slice-level policy decision)
  - `capture_id` (UUID; window identity)
  - `timestamp_start` / `timestamp_end`

- Capture parameters (declared by client; server-enforced caps apply):
  - Target resolution (≤ 480p in Sprint 1)
  - Target FPS (≤ 15 in Sprint 1)
  - Encoding (e.g., `image/jpeg`)

### Capture Parameters (Sprint 1 Policy)

In Sprint 1, capture parameters are declared by the browser client in
`capture.open` and enforced server-side.

Declared by client:
- Target resolution
- Target FPS
- Encoding (e.g., `image/jpeg`)

Server behavior:
- Enforces hard caps (duration, FPS, resolution, total frames/bytes)
- May clamp or normalize effective parameters
- Returns accepted parameters in `capture.ack`

The server does not own or configure OS-level camera devices in Sprint 1.

### Transport Identity Semantics

WebSocket control messages reuse selected BaseSchema-style metadata fields:

- `schema_version`
- `record_id`
- `user_id`
- `session_id`

These fields are used strictly as **transport metadata**.

`record_id`:
- Identifies a single control message
- Must be unique per WebSocket connection
- Is not persisted
- Is not globally unique
- Is not generated by this module

This module:
- Validates presence of required IDs
- Does not generate `record_id`, `session_id`, or `capture_id`
- Does not emit A3CPMessage





## Outputs
- Validated bounded capture windows (in-memory) forwarded to downstream consumers
- Encoded video frames (e.g., JPEG bytes) with associated metadata
- Capture-level summary metadata (frames received, duration, bytes)
- Error signals (e.g., guardrail violation, malformed payload, session invalid)

This module does not emit schema-compliant messages directly. It forwards validated capture data and metadata to downstream modules (e.g., `landmark_extractor`). Schema wrapping into `A3CPMessage` or other schema types is performed downstream.


## OUTPUT PAYLOAD FORMAT (internal)
This module forwards bounded capture windows as in-memory data structures,
suitable for downstream processing (e.g., `landmark_extractor`) without disk writes.

Capture window representation:

{
  "capture_id": <UUID string>,            # Window identity (authoritative from client)
  "user_id": <string>,
  "session_id": <string>,
  "timestamp_start": <ISO 8601 string>,   # Event-time from client
  "timestamp_end": <ISO 8601 string>,     # Event-time from client
  "encoding": <string>,                   # e.g., "image/jpeg"
"frames": [
  {
    "seq": <int>,
    "timestamp": <ISO 8601 string>,
    "content_type": <string>,
    "bytes": <binary>,   # In-memory only (not JSON-serializable)
    "byte_length": <int>
  },
  ...
]

Note:
- This structure is an in-process Python data structure.
- `bytes` are never serialized to JSON.
- No temporary files or disk writes are permitted in Sprint 1.

This format must be:
- Buffered in memory only (no temp files, no disk writes)
- Enforced by guardrails (duration/FPS/resolution/bytes)
- Forwarded to consumers via a service/repository boundary
- Interpreted by consumers for schema wrapping and logging (schema_recorder only)



## Runtime Considerations
- WebSocket ingest must be non-blocking and resilient under bursty frame delivery
- Must enforce guardrails and backpressure (drop/close) without unbounded memory growth
- Must expose a clean forwarding interface (e.g., async call or in-memory queue) for downstream vision modules/classifiers
- Ingest failures (malformed messages, disconnects, limit violations) must be recoverable and produce diagnostic logs
- Must allow graceful shutdown/restart across sessions (close active captures; release buffers)


---

## Design Rationale
The `camera_feed_worker` was split out of the former `video_streamer` module to enforce separation of concerns. This submodule is solely responsible for robust, real-time frame capture from a video device.

### Architectural decisions:
- **No side effects**: This module performs no inference, transformation, or disk writes.
- **Deterministic timestamps**: Frames are timestamped immediately after capture for alignment with audio or event logs.
- **Upstream agnostic**: The source can be a webcam, virtual camera, or test stream; the interface remains uniform.
- **Resilience-first**: Emphasis on handling hardware failures, disconnections, or high-latency conditions gracefully.

---

## Edge Case Handling
- If browser camera permissions are denied or no camera is available, client must surface an actionable error; server receives no frames.
- If the client starts a capture but sends no frames (idle), server must auto-close on idle timeout with an error/summary.
- Frames may be dropped under load; server should log drops and enforce caps (max buffer, max frames/bytes).
- Timestamps must be validated for sane ordering; do not require monotonic clocks, but reject clearly invalid sequences.
- Disconnect mid-capture must abort the window cleanly (close + error/summary) and release memory buffers.
- Provide a simulated client mode for dev/test (generated frames, no disk persistence).


---

## Known Issues / Risks
- Hardware indexing may vary across platforms (e.g., `/dev/video0` vs index `1`)
- Frame read latency can spike on some systems when resolution is changed dynamically
- Threading or GIL-related capture bugs are possible if OpenCV is not isolated
- In environments like Streamlit, `cv2.VideoCapture()` may hang or fail silently — Django/WSGI likely avoids this
- MediaPipe pipeline compatibility depends on input frame format; pre-checks may be required

---

## Development TODOs
- [ ] Implement WebSocket ingest for bounded capture windows (`capture.open/frame/close`)
- [ ] Enforce guardrails (duration/FPS/resolution/frames/bytes) server-side
- [ ] Validate and propagate `session_id` + `capture_id` + timestamps
- [ ] Forward window payload (memory-only) to `landmark_extractor` (define boundary)
- [ ] Add logging for ingest start/close, errors, drops, and limit rejections
- [ ] Define minimal metadata model(s) for capture/window + per-frame headers (transport envelope, not A3CPMessage)
- [ ] Add dev/test client mode (simulated frames) for deterministic tests (no disk persistence)


---

## Known Issues / Risks
- Browser capture constraints may vary across devices (camera resolution, FPS limits, codec support)
- Network latency or bandwidth limits may affect frame delivery and effective FPS
- Large capture windows may trigger server guardrail rejections (duration/bytes/frame caps)
- Out-of-order or dropped WebSocket frames must be handled defensively
- MediaPipe or downstream pipeline compatibility depends on frame encoding and format; validation required
- Disconnects mid-capture must be handled cleanly (abort + summary/error)


---

## Integration Notes
- **To downstream vision modules (e.g., `landmark_extractor`, object classifiers)**:
  Bounded capture windows are forwarded via a defined service/repository boundary
  (async call or in-memory buffer; no disk persistence).

- **To `schema_recorder`**:
  No direct writes. Any schema-compliant events are emitted by downstream modules
  and recorded exclusively via `schema_recorder.service`.

- **From `session_manager`**:
  Receives and validates `session_id` (no device configuration injection in Sprint 1).

- **Transport boundary**:
  Ingest occurs via WebSocket; frames are encoded bytes with metadata,
  not Python-native `np.ndarray` objects.


-------------------------------------------------------------------------------
⚠ SCHEMA COMPLIANCE DISCLAIMER
-------------------------------------------------------------------------------

This module does **not** emit schema-compliant records (e.g., `A3CPMessage`).

It streams raw video frames and metadata. Schema wrapping is the responsibility
of downstream consumers such as `landmark_extractor` or `schema_recorder`.

Consumers must:
- Interpret the timestamp and ID metadata for alignment
- Insert schema-required fields (`modality="image"`, `source="communicator"`)
- Produce logs compatible with `SCHEMA_REFERENCE.md`


## References
- [`SCHEMA_REFERENCE.md`](../../schemas/SCHEMA_REFERENCE.md) — field definitions for video input records
- [`gesture_classifier/README.md`](../gesture_classifier/README.md) — for downstream consumer expectations
- [`camera_feed_architecture.drawio`](./diagrams/camera_feed_architecture.drawio) — architecture diagram (WIP)
- A3CP Design Doc v3 – Section 6.2 (Visual Stream Stack)
- MediaPipe Holistic documentation: https://developers.google.com/mediapipe/solutions/vision/holistic
